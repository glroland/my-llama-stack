version: '2'
distribution_spec:
  description: home.glroland.com's LLama Stack Distribution for Smart Lab Applications
  container_image: null #registry.access.redhat.com/ubi9/python-311:9.6-1747333117
  providers:
    inference:
    - provider_type: remote::ollama
    - provider_type: inline::sentence-transformers
    - provider_type: remote::vllm
    - provider_type: remote::openai
    - provider_type: remote::bedrock
    - provider_type: remote::passthrough
    - provider_type: remote::together
    vector_io:
    - provider_type: inline::faiss
    - provider_type: remote::milvus
    - provider_type: remote::pgvector
    files:
    - provider_type: inline::localfs
    safety:
    - provider_type: inline::llama-guard
    - provider_type: inline::code-scanner
    agents:
    - provider_type: inline::meta-reference
    telemetry:
    - provider_type: inline::meta-reference
    post_training:
#    - provider_type: inline::huggingface
    - provider_type: inline::torchtune-cpu
    eval:
    - provider_type: inline::meta-reference
    datasetio:
    - provider_type: remote::huggingface
    - provider_type: inline::localfs
    scoring:
    - provider_type: inline::basic
    - provider_type: inline::llm-as-judge
    - provider_type: inline::braintrust
    tool_runtime:
    - provider_type: remote::tavily-search
    - provider_type: inline::rag-runtime
    - provider_type: remote::model-context-protocol
    - provider_type: remote::wolfram-alpha
    batches:
    - provider_type: inline::reference
image_type: container
additional_pip_packages:
- aiosqlite
- sqlalchemy[asyncio]
- blobfile
- asyncpg
- psycopg2-binary
