# Typically, which LLama Stack distro this image is generated from
ARG LLAMA_STACK_TAG=my-llama-stack

FROM llama-stack:${LLAMA_STACK_TAG}

# Setup run configuration
ENV RUN_CONFIG_PATH=/app/run.yaml
ADD run.yaml /app/run.yaml

# Add database configuration variables (separated into 2 databases)
ENV POSTGRES_DB_SQL "llamastack_sql"
ENV POSTGRES_DB_KV "llamastack_kv"

# Prep working directories in file system
RUN mkdir -p /.llama/distributions

RUN chgrp -R 0 /.llama && \
    chmod -R g+rwX /.llama

# Store cache in llama storage dir
RUN rm -rf /.cache && \
    mkdir -p /llama-storage && \
    ln -s /llama-storage /.cache

# Download Hugging Face Models
RUN hf download sentence-transformers/all-mpnet-base-v2 --exclude "onnx/*" --exclude "openvino/*"
RUN hf download nomic-ai/nomic-embed-text-v1.5 --exclude "onnx/*"
RUN hf download ibm-granite/granite-embedding-125m-english

#
# for UI, enable node
#

# Debian based install of node
RUN apt-get update && \
    apt-get install -y curl gnupg && \
    curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y nodejs && \
    rm -rf /var/lib/apt/lists/*

# RHEL based install of node
#RUN dnf module enable -y nodejs:18 && \
#    dnf install -y nodejs npm && \
#    dnf clean all

RUN chown -R 1001 /.llama

USER 1001

ENTRYPOINT ["/usr/local/bin/llama-stack-entrypoint.sh"]
